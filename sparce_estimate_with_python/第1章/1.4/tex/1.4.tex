\documentclass{jsarticle}
\usepackage{amsmath,amssymb}
\usepackage{enumerate}
\usepackage{breqn}
\usepackage{amsthm}
\theoremstyle{definition}
\usepackage{bm}
%\newtheorem{Ex}{演習問題}
%\newtheorem*{Ex*}{演習問題}
\newtheoremstyle{mystyle}%   % スタイル名
    {}%                      % 上部スペース
    {}%                      % 下部スペース
    {\normalfont}%           % 本文フォント
    {}%                      % インデント量
    {\bf}%                   % 見出しフォント
    {}%                      % 見出し後の句読点, '.'
    { }%                     % 見出し後のスペース, ' ' or \newline
    {\underline{\thmname{#1}\thmnumber{#2}\thmnote{（#3）}}}%
                             % 見出しの書式 (can be left empty, meaning `normal')
\theoremstyle{mystyle} % スタイルの適用
\newtheorem*{Def}{Def}
\newtheorem*{theo}{Theorem}
\newtheorem*{lem}{Lemma}
\newtheorem*{ex}{Example}
\newtheorem*{col}{Corollary}
\renewcommand{\footnotesize}{\normalsize}
\usepackage{latexsym}
\usepackage{emathEy}
\def\qed{\hfill$\Box$}

\begin{document}
\large
\section*{1.3の補足}
最初に$\lambda$の値を十分大きくして全ての$\beta_j$を$0$に設定した後，$\lambda$の値を下げながら，座標降下法を実行することを考える．簡単のため，各$j=1,\cdots,p$について$\displaystyle\sum_{i=1}^Nx_{i,j}^2=1$であって，$\displaystyle\sum_{i=1}^Nx_{i,j}y_i$の値が全て異なると仮定する．このとき，全ての$j$に対して$\beta_j=0$であるような$\lambda$の値は$\lambda = \displaystyle\max_{1\leq j\leq p}\left|\frac{1}{N}\sum_{i=1}^Nx_{i,j}y_i\right|$で与えられる；\\
$\beta_j$を1つ選び，そのほかの$\beta_k$は$0$として固定する．このとき，(1.10)式から$L$の劣微分を$0$にするような$\beta_j$を求めると
\begin{align*}
&-\frac{1}{N}\sum_{i=1}^Nx_{i,j}\left(y_i-\sum_{k=1}^px_{i,k}\beta_k\right)+\lambda\begin{cases}
1 & \beta_j>0\\
[-1,1] & \beta_j = 0\\
-1 & \beta_j<0
\end{cases}\\
&=-\frac{1}{N}\sum_{i=1}^Nx_{i,j}y_i+\frac{1}{p}\sum_{i=1}^Nx_{i,j}^2\beta_j+\lambda\begin{cases}
1 & \beta_j>0\\
[-1,1] & \beta_j = 0\\
-1 & \beta_j<0
\end{cases}\quad(\because \beta_k = 0\;\;(k\neq j))\\
&=-\frac{1}{N}\sum_{i=1}^Nx_{i,j}y_i+\frac{1}{N}\beta_j +\lambda\begin{cases}
1 & \beta_j>0\\
[-1,1] & \beta_j = 0\\
-1 & \beta_j<0
\end{cases}\ni 0\quad\left(\because \sum_{i=1}^Nx_{i,j}^2=1\right)\\
\therefore \beta_j &= N\mathcal{S}_{\lambda}\left(\frac{1}{N}\sum_{i=1}^Nx_{i,j}y_i\right) = 0\quad\left(\because \lambda\geq \max_{1\leq j\leq p}\left|\frac{1}{N}\sum_{i=1}^Nx_{i,j}y_i\right|\right)
\end{align*}
となるからである．もし$\lambda$をその値より小さくすると，ある1つの$j$で$p_j = \displaystyle\frac{1}{N}\sum_{i=1}^Nx_{i,j}y_i$としたときに
$$\beta_j =  N\mathcal{S}_{\lambda}\left(p\right)= N\begin{cases}
p-\lambda & (p>\lambda)\\
p + \lambda & (p<\lambda)
\end{cases}$$
となるので
\begin{align*}
\frac{1}{N}\left|\sum_{i=1}^Nx_{i,j}\left(y_i-\sum_{k=1}^px_{i,k}\beta_k\right)\right| &= \frac{1}{N}\left|\sum_{i=1}^N x_{i,j}y_i - \sum_{k=1}^Nx_{i,j}^2 \beta_j\right|\\
&=\frac{1}{N}|N\lambda|=\lambda
\end{align*}
が成立する．\\






\section*{Ridge}
1.1節において，行列$X^TX$が正則であるという仮定の下で二乗誤差$\|y-X\beta\|$を最小にする$\beta$が$\hat{\beta}=(X^TX)^{-1}X^T y$となることを導いた．\\
その後$N<p$の場合には$X^T X$が正則でないことを示したが，$N\geq p$であって$X^T X$が正則であっても，行列式が小さければ信頼区間が大きくなるなど不都合が生じる．このような問題を避けるため，定数$\lambda\geq 0$を用いて二乗誤差に$\beta$のノルムの$\lambda$倍を加えた
$$L:=\frac{1}{N}\|y-X\beta\|^2+\lambda\|\beta\|^2$$
を最小にする方法がよく用いられる．この方法をRidgeと呼ぶ．上式を最小にする$\beta$を求めるために，$L$を$\beta$で微分すると
$$\frac{\partial L}{\partial \beta}=-\frac{2}{N}X^T(y-X\beta)+2\lambda\beta$$
となる．(ベクトル微分の公式 $\partial/\partial {\bm x}(A{\bm x}-{\bm b})^T(A{\bm x}-{\bm b})=2A^T(A{\bm x}-{\bm b})$を用いた．)さらに$X^TX+N\lambda I$が正則であれば，$\frac{\partial L}{\partial \beta}=0$となる$\hat{\beta}$は
\begin{align*}
0 &=-\frac{2}{N}X^T(y-X\beta)+2\lambda\beta\\
&=\frac{2}{N}X^T y-\frac{2}{N}(X^TX+ N\lambda)\hat{\beta}\\
(X^TX - N\lambda)\hat{\beta}&= X^T y\\
\hat{\beta} &=(X^TX +N\lambda)^{-1}X^Ty
\end{align*}
となることがわかる．ここで，$\lambda>0$ならば$X^TX+ N \lambda$が正則になることがわかる．証明は以下の通り
\begin{proof}
まず，$(X^T X)^T =X^T X$が成立するので$X^T X$は対称行列となる．さらに任意の${\bm x}\in\mathbb{R}^p$に対して
\begin{align*}
{\bm x}^T (X^T X){\bm x}&=({\bm x}^T X^T )(X{\bm x})\\
&=({\bm x}X)^T({\bm x} X)
\end{align*}
となり，最右辺は${\bm x}X$自身の内積を示しているので${\bm x}^T (X^T X){\bm x}\geq 0$であること，つまり$X^T X$が非負定値行列であることがわかる．さらに$X^T X$は対称行列であるから，ある直交行列$P$と対角行列$\Lambda$を用いて
$$X^T X = P^{-1} \Lambda P$$
と表すことができる．今$e_i $を$\mathbb{R}^p$の標準基底とすると，
\begin{align*}
(P^{-1} e_i )^T(X^T X)(P^{-1}e_i) &=((P^{-1}e_i)^T P^{-1})\Lambda (P(P^{-1}e_i))\\
&=(P(P^{-1}e_i)\Lambda (e_i)\quad (\because P^{-1}=P^T)\\
&=e_i^T \Lambda e_i = \mu_i\geq 0
\end{align*}
となることがわかる．ただし$\mu_i$は$\Lambda$の$(i,i)$成分．したがって任意の$\lambda$に対して$\mu_i\geq 0$であることがわかり，各$\mu_i$は$X^T X$の固有値であることから$X^T X$の全ての固有値が非負であることがわかる．さらに，$X^TX- n \lambda$の固有値を$t$とすると
\begin{align*}
{\rm det}|(X^T X+ N\lambda )- tI|&={\rm det}|X^T X-(t-N\lambda)I|=0\\
&\Rightarrow t-N \lambda=\mu_i\geq 0\quad \forall i\\
&\Leftrightarrow t = N\lambda +\mu_i >0  \quad \forall i
\end{align*}
が成立するので$X^TX- n \lambda$の固有値が全て正であることがわかり，これより$X^TX$の行列式が$0$でないことがわかる．したがって$X^T X$が正則であることがわかる．\\
\end{proof}



\end{document}